# üî¨ Data Science & ML Protocol for Cursor

## üìñ –û–ø–∏—Å–∞–Ω–∏–µ

–ü—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ Data Science –∏ Machine Learning —Å Cursor AI.

## üéØ –°—Ñ–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

- Data Analysis –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- Machine Learning –º–æ–¥–µ–ª–∏
- ETL –ø–∞–π–ø–ª–∞–π–Ω—ã
- Jupyter Notebook —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- Data preprocessing –∏ –æ—á–∏—Å—Ç–∫–∞
- Feature Engineering

## üîÑ –†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å

### –§–ê–ó–ê 1: Data Architect (–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ Senior Data Scientist.

#### –ó–∞–¥–∞—á–∏:
1. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
2. –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞/–º–æ–¥–µ–ª–µ–π
3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞
4. –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

#### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (STRICT):
- ‚ùå –ù–ï –ø–∏—à–∏ –∫–æ–¥ –≤ —ç—Ç–æ–π —Ñ–∞–∑–µ
- ‚ùå –ù–ï —Å–æ–∑–¥–∞–≤–∞–π —Ñ–∞–π–ª—ã
- ‚úÖ –¢–æ–ª—å–∫–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑

#### –í—ã—Ö–æ–¥ (Deliverables):
```markdown
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: [Feature Name]

## –ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: [Tabular/Time Series/Text/Images]
- –û–±—ä—ë–º: [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫/—Ñ–∞–π–ª–æ–≤]
- –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: [–∞–Ω–∞–ª–∏–∑]
- –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: [–æ–ø–∏—Å–∞–Ω–∏–µ]

## –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
- [–ú–µ—Ç–æ–¥ 1]: [–æ–ø–∏—Å–∞–Ω–∏–µ]
- [–ú–µ—Ç–æ–¥ 2]: [–æ–ø–∏—Å–∞–Ω–∏–µ]

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
```
project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îú‚îÄ‚îÄ processed/                # –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îî‚îÄ‚îÄ features/                # Feature engineering
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter Notebooks
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # ML –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/           # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ outputs/
```

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
- Python 3.10+
- pandas, numpy, scipy
- scikit-learn / xgboost / lightgbm
- matplotlib / seaborn / plotly
- Jupyter Notebook
```

**–§–ê–ó–ê 1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ñ–¥—É —Ñ–∞–∑—É 2.**
```

### –§–ê–ó–ê 2: Data Engineer (–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ Data Engineer.

#### –¢–≤–æ–π —Å—Ç–µ–∫ (STRICT):
```yaml
Language:
  - Python 3.10+
  - Type hints –≤–∫–ª—é—á–µ–Ω—ã

Data Processing:
  - pandas –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - numpy –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
  - scipy –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
  - scikit-learn –¥–ª—è ML

Visualization:
  - matplotlib –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
  - seaborn –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
  - plotly –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤

Notebooks:
  - Jupyter Notebook / JupyterLab
  
Testing:
  - pytest
  - Coverage target: 80%
```

#### –ó–∞–ø—Ä–µ—â–µ–Ω–æ (STRICT):
```yaml
‚ùå Excel / Spreadsheet –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–π python/pandas)
‚ùå VBA macros
‚ùå –ü—Ä—è–º—ã–µ SQL –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ ORM
‚ùå "–ú–∞–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ" –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
‚ùå –ë–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ code golf (–∫–æ—Ä–æ—Ç–∫–∏–π –±–µ–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏)
```

#### –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:

1. **Data Loading:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
import pandas as pd
from pathlib import Path

# –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø—ã
df = pd.read_csv('data.csv', dtype={
    'id': 'int64',
    'price': 'float64',
    'date': 'str'
})

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
df = pd.read_csv('data.csv', na_values=['NA', '-'])

# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
df = pd.read_csv('data.csv')  # –ù–µ—Ç —Ç–∏–ø–æ–≤, –Ω–µ—è–≤–Ω–æ–µ
```

2. **Data Cleaning:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
import pandas as pd
import numpy as np

# –ß–∏—Å—Ç–∫–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
df_cleaned = df.dropna(subset=['email', 'phone'])
print(f"–£–¥–∞–ª–µ–Ω–æ {len(df) - len(df_cleaned)} —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ —Å IQR
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1
df_cleaned = df[(df['price'] >= Q1 - 1.5*IQR) & 
                (df['price'] <= Q3 + 1.5*IQR)]

# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
df_cleaned = df.drop(df[df['price'] > 1000].index)  # –ë–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
```

3. **Feature Engineering:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
import pandas as pd
from sklearn.preprocessing import StandardScaler

# –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ skewed –¥–∞–Ω–Ω—ã—Ö
df['log_price'] = np.log1p(df['price'])

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
df['price_category'] = pd.cut(df['price'], bins=5, labels=['Low', 'Medium-Low', 'Medium', 'Medium-High', 'High'])

# One-hot encoding
df_encoded = pd.get_dummies(df, columns=['category', 'type'])

# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
df['category'] = df['category'].astype('category')  # –ë–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏
df['price_category'] = np.where(df['price'] > 100, 'high', 'low')  # Hardcoded threshold
```

4. **Model Training:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# –Ø–≤–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# –û–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)

model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
import joblib
joblib.dump(model, 'models/random_forest.joblib')

# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
model.fit(X, y)  # –ë–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ train/test
model.predict(X_test)  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
```

5. **Documentation:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
"""
Data Preprocessing Pipeline

This module contains functions for data cleaning and feature engineering.

Functions:
- clean_data(df): Removes duplicates and handles missing values
- engineer_features(df): Creates new features from existing data
- normalize_data(df): Scales numerical features

Example:
>>> from src.preprocessing import clean_data, engineer_features
>>> df = pd.read_csv('data.csv')
>>> df_clean = clean_data(df)
>>> df_enhanced = engineer_features(df_clean)
"""

def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean data by removing duplicates and handling missing values."""
    # Implementation
    pass
```

#### –ß–µ–∫–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º:
- [ ] –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (—Ç–∏–ø—ã —É–∫–∞–∑–∞–Ω—ã)
- [ ] –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
- [ ] –í—ã–±—Ä–æ—Å—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
- [ ] –§–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã –ª–æ–≥–∏—á–Ω–æ
- [ ] –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
- [ ] –ö–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
- [ ] –¢–µ—Å—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω—ã (coverage >= 80%)
- [ ] Notebook –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω (—è—á–µ–π–∫–∏, markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏)

### –§–ê–ó–ê 3: Model Validator (–ü—Ä–æ–≤–µ—Ä–∫–∞)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ ML Validator.

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–µ–∫–∞:
```python
# ‚ùå FAIL –µ—Å–ª–∏:
import xlrd  # –ò—Å–ø–æ–ª—å–∑—É–π pandas
from statsmodels import OLS  # –ò—Å–ø–æ–ª—å–∑—É–π scikit-learn

# ‚úÖ PASS –µ—Å–ª–∏
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
```

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞:
```python
# ‚ùå FAIL –µ—Å–ª–∏:
- –§—É–Ω–∫—Ü–∏—è > 50 —Å—Ç—Ä–æ–∫ –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
- –ù–µ—Ç type hints
- –ú–∞–≥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞ –±–µ–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç
- –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫

# ‚ùå FAIL –µ—Å–ª–∏:
- –ù–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö
- –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –º–µ—Ç–æ–¥–∞–º
```

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ ML best practices:
```python
# ‚ùå FAIL –µ—Å–ª–∏:
- –ù–µ—Ç train/test split
- –ù–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
- –ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ (accuracy, precision, recall, F1)
- –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤

# ‚úÖ PASS –µ—Å–ª–∏:
- train_test_split —Å stratify
- –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
- classification_report –¥–ª—è –º–µ—Ç—Ä–∏–∫
- –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
```

#### –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:

**–ï–°–õ–ò –û–®–ò–ë–ö–ê:**
```markdown
‚õî VALIDATION FAILED

–ü—Ä–∏—á–∏–Ω–∞: [–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞]
–§–∞–π–ª: [filename.ipynb]
–°—Ç—Ä–æ–∫–∞: [line number]

–ù–∞—Ä—É—à–µ–Ω–∏–µ:
- [–ü—Ä–∞–≤–∏–ª–æ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞]
- [–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ]

–î–µ–π—Å—Ç–≤–∏–µ: –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∫–æ–¥, —Å–æ–±–ª—é–¥–∞—è –ø—Ä–æ—Ç–æ–∫–æ–ª
–í–æ–∑–≤—Ä–∞—Ç –∫ –§–ê–ó–ï 2
```

**–ï–°–õ–ò –í–°–Å OK:**
```markdown
‚úÖ VALIDATION PASSED

–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:
- ‚úÖ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ —Å–æ–±–ª—é–¥—ë–Ω
- ‚úÖ ML best practices –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
- ‚úÖ Data preprocessing –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç

–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
```

## üîß Rabbit Hole Detection

–ï—Å–ª–∏ –æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è 2 —Ä–∞–∑–∞:

1. **–û—Å—Ç–∞–Ω–æ–≤–∏—Å—å** –∏ –ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –ø–æ–ø—ã—Ç–∫—É
2. **–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π** –ø—Ä–æ–±–ª–µ–º—É –≤ `docs/DEBUG_REPORT.md`
3. **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π**:
   - –≠—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ (–Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–µ—Ç–æ–¥)?
   - –≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (–∫–∞—á–µ—Å—Ç–≤–æ/–æ–±—ä—ë–º)?
   - –≠—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏ (–ø–∞–º—è—Ç—å/—Å–∫–æ—Ä–æ—Å—Ç—å)?

4. **–ü—Ä–µ–¥–ª–æ–∂–∏** –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∞ –∏–ª–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–π –ø–æ–º–æ—â—å

## üìã –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –°–æ–∑–¥–∞–Ω–∏–µ ETL –ø–∞–π–ø–ª–∞–π–Ω–∞

**–ó–∞–ø—Ä–æ—Å:**
> –°–æ–∑–¥–∞–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–æ–≤

**–§–ê–ó–ê 1 - Data Architect:**
```markdown
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: ETL Pipeline –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö

## –ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- –ò—Å—Ç–æ—á–Ω–∏–∫: CSV —Ñ–∞–π–ª—ã –≤ data/raw/
- –û–±—ä—ë–º: ~1M –∑–∞–ø–∏—Å–µ–π
- –ü–æ–ª—è: id, product_id, quantity, price, date

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
```
project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # –í—Ö–æ–¥–Ω—ã–µ CSV
‚îÇ   ‚îú‚îÄ‚îÄ processed/             # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îî‚îÄ‚îÄ aggregated/           # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ etl_pipeline.py      # –û—Å–Ω–æ–≤–Ω–æ–π ETL —Å–∫—Ä–∏–ø—Ç
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 02_aggregation.ipynb
‚îî‚îÄ‚îÄ tests/
```

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
- Python 3.10+
- pandas –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- sqlite –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
```
```

**–§–ê–ó–ê 2 - Data Engineer:**
```python
import pandas as pd
from pathlib import Path

# ETL Pipeline
class ETLPipeline:
    def __init__(self):
        self.raw_path = Path('data/raw')
        self.processed_path = Path('data/processed')
        self.aggregated_path = Path('data/aggregated')
        
    def extract(self):
        """Extract data from raw files."""
        files = list(self.raw_path.glob('*.csv'))
        dfs = []
        for file in files:
            df = pd.read_csv(file)
            # Remove duplicates
            df = df.drop_duplicates()
            dfs.append(df)
        return pd.concat(dfs, ignore_index=True)
    
    def transform(self, df):
        """Transform data: aggregate sales by product."""
        aggregated = df.groupby('product_id').agg({
            'quantity': 'sum',
            'total_revenue': lambda x: (x['quantity'] * x['price']).sum()
        }).reset_index()
        return aggregated
    
    def load(self, df):
        """Load processed data to SQLite."""
        import sqlite3
        conn = sqlite3.connect('data/sales.db')
        df.to_sql('sales', conn, if_exists='replace', index=False)
        conn.close()
    
    def run(self):
        """Run full ETL pipeline."""
        print("üì• Extracting data...")
        df = self.extract()
        
        print("üîÑ Transforming data...")
        df_transformed = self.transform(df)
        df_transformed.to_csv(self.processed_path / 'sales.csv', index=False)
        
        print("üíæ Loading to database...")
        self.load(df_transformed)
        
        print("‚úÖ ETL pipeline completed")
```

**–§–ê–ó–ê 3 - Model Validator:**
```markdown
‚úÖ VALIDATION PASSED

–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:
- ‚úÖ pandas –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (–Ω–µ Excel)
- ‚úÖ SQLite –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
- ‚úÖ Pipeline —Ä–∞–∑–¥–µ–ª—ë–Ω –Ω–∞ —ç—Ç–∞–ø—ã
- ‚úÖ –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ª–æ–≥–∏—á–Ω–∞
- ‚úÖ –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è
```

---

## üöÄ –ß–∞—Å—Ç—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

### S1: Exploratory Data Analysis
1. **Data Architect:** –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
2. **Data Engineer:** –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, —Å–æ–∑–¥–∞—Ç—å –Ω–æ—É—Ç–±—É–∫–∏
3. **Model Validator:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞

### S2: ML Model Development
1. **Data Architect:** –°–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
2. **Data Engineer:** –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
3. **Model Validator:** –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏

### S3: Feature Engineering
1. **Data Architect:** –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–∏—á–∏
2. **Data Engineer:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å feature engineering
3. **Model Validator:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏

---

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

- [Data Science Notebook Template](../../examples/data-science-notebook.md)
- [README.md](../../README.md) ‚Äî –û–±—â–µ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
