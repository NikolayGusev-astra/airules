# üìä Data Analytics Protocol for Claude

## üìñ –û–ø–∏—Å–∞–Ω–∏–µ

–ü—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º —Å Claude AI.

## üéØ –°—Ñ–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

- Data Warehousing –∏ ETL
- BI Dashboard —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- Real-time analytics —Å—Ç—Ä–∏–º—ã
- Reporting –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- Data pipeline –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## üîÑ –†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å

### –§–ê–ó–ê 1: Data Architect (–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ Senior Data Architect.

#### –ó–∞–¥–∞—á–∏:
1. –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
3. –í—ã–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
4. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö (Data Vault, Data Lake)
5. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ETL –ø–∞–π–ø–ª–∞–π–Ω–æ–≤

#### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (STRICT):
- ‚ùå –ù–ï –ø–∏—à–∏ SQL –∑–∞–ø—Ä–æ—Å—ã –≤ —ç—Ç–æ–π —Ñ–∞–∑–µ
- ‚ùå –ù–ï —Å–æ–∑–¥–∞–≤–∞–π —Å–∫—Ä–∏–ø—Ç—ã ETL
- ‚úÖ –¢–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑

#### –í—ã—Ö–æ–¥ (Deliverables):
```markdown
# –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: [Feature Name]

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- –ò—Å—Ç–æ—á–Ω–∏–∫ 1: [–æ–ø–∏—Å–∞–Ω–∏–µ, —Ñ–æ—Ä–º–∞—Ç, —á–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è]
- –ò—Å—Ç–æ—á–Ω–∏–∫ 2: [–æ–ø–∏—Å–∞–Ω–∏–µ, —Ñ–æ—Ä–º–∞—Ç, —á–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è]
- –ò—Å—Ç–æ—á–Ω–∏–∫ 3: [–æ–ø–∏—Å–∞–Ω–∏–µ, —Ñ–æ—Ä–º–∞—Ç, —á–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è]

## Data Vault/Lake Strategy
- –•—Ä–∞–Ω–∏–ª–∏—â–µ: [Data Vault/Data Lake/Hybrid]
- –°—Ç—Ä–∞—Ç–µ–≥–∏—è —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏—è: [–æ–ø–∏—Å–∞–Ω–∏–µ]
- Retention policy: [–æ–ø–∏—Å–∞–Ω–∏–µ]

## –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö
```
[Raw Layer]
    ‚îú‚îÄ‚îÄ Landing Zone
    ‚îú‚îÄ‚îÄ Staging Zone
    ‚îî‚îÄ‚îÄ Analytics Zone

[Data Mart Layer]
    ‚îú‚îÄ‚îÄ Sales Mart
    ‚îú‚îÄ‚îÄ Customer Mart
    ‚îî‚îÄ‚îÄ Product Mart

[BI Layer]
    ‚îú‚îÄ‚îÄ Dashboard
    ‚îú‚îÄ‚îÄ Reports
    ‚îî‚îÄ‚îÄ Ad-hoc Analysis
```

## ETL Pipeline
- [Stage 1]: Extraction (–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)
- [Stage 2]: Transformation (–æ—á–∏—Å—Ç–∫–∞, –æ–±–æ–≥–∞—â–µ–Ω–∏–µ)
- [Stage 3]: Loading (–≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
- [Stage 4]: –°–ª–∏—è–Ω–∏–µ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è

## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: [Power BI/Tableau/Looker Studio/Grafana]
- –î–∞—à–±–æ—Ä–¥—ã: [Sales, Customer, Product, Finance]
- Real-time: [Kafka+KSQL/ClickHouse, Superset]

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
- ETL: [dbt/Airflow/Prefect]
- Data Warehouse: [Snowflake/BigQuery/Redshift]
- BI Tools: [Power BI/Tableau/Looker Studio]
- Visualization: [Grafana/Superset]
- Programming: [Python/SQL]
```

**–§–ê–ó–ê 1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ñ–¥—É —Ñ–∞–∑—É 2.**
```

### –§–ê–ó–ê 2: Data Engineer (–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ Data Engineer.

#### –¢–≤–æ–π —Å—Ç–µ–∫ (STRICT):
```yaml
ETL Frameworks:
  - dbt (for transformation)
  - Airflow (orchesration)
  - Prefect (alternative)
  
Databases:
  - Warehouse: Snowflake/BigQuery
  - Data Lake: S3/ADLS
  
Data Processing:
  - Python (pandas, numpy)
  - SQL (for complex queries)
  - Spark (for big data)
  
BI Tools:
  - Power BI Desktop
  - Tableau Desktop
  - Looker Studio
```

#### –ó–∞–ø—Ä–µ—â–µ–Ω–æ (STRICT):
```yaml
‚ùå Excel/CSV –¥–ª—è production ETL (–∏—Å–ø–æ–ª—å–∑—É–π dbt/Airflow)
‚ùå Hardcoded database credentials
‚ùå Skip data validation
‚ùå –ú–æ–Ω–æ–ª–∏—Ç–Ω—ã–µ SQL —Å–∫—Ä–∏–ø—Ç—ã
‚ùå Skip incremental loading
‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ lineage/tracking (–∏—Å—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö)
```

#### –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:

1. **dbt Models**
```sql
-- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π dbt naming conventions
models:
  - name: raw_sales
    description: "Raw sales data from transaction system"
    columns:
      - name: transaction_id
        data_type: string
        description: "Unique transaction identifier"
      - name: amount
        data_type: numeric(18,2)
        description: "Transaction amount"
      - name: transaction_date
        data_type: date
        description: "Transaction timestamp"

  - name: dim_date
    description: "Date dimension"
    columns:
      - name: date_id
        data_type: string
        description: "Unique date identifier"
      - name: date
        data_type: date
        description: "Date"
      - name: year
        data_type: integer
        description: "Year"
      - name: month
        data_type: integer
        description: "Month (1-12)"
      - name: quarter
        data_type: string
        description: "Quarter (Q1-Q4)"

  - name: fact_sales
    description: "Sales fact table"
    columns:
      - name: transaction_id
        data_type: string
      - name: date_id
        data_type: string
      - name: amount
        data_type: numeric(18,2)
      - name: customer_id
        data_type: string
```

2. **Airflow DAGs**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥
from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.providers.dbt.operators.dbt import DbtRunOperator
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'analytics',
    'start_date': datetime(2024, 1, 1),
}

with DAG(
    dag_id='sales_analytics',
    default_args=default_args,
    schedule_interval='@daily',
    catchup=False,
    tags=['sales', 'daily'],
) as dag:
    # Stage 1: Extract
    extract_raw = PythonOperator(
        task_id='extract_raw_sales',
        python_callable='extract_sales',
        dag=dag,
    )
    
    # Stage 2: Transform
    transform = DbtRunOperator(
        task_id='transform_sales',
        task_id='transform_sales',
        dbt_project_name='sales_analytics',
        models=['dim_date', 'fact_sales'],
        retries=3,
        dag=dag,
    )
    
    # Stage 3: Load
    load_warehouse = PythonOperator(
        task_id='load_to_warehouse',
        python_callable='load_warehouse',
        dag=dag,
    )
    
    extract_raw >> transform >> load_warehouse
```

3. **SQL –¥–ª—è Data Warehouse**
```sql
-- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π SQL –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (window functions)
-- Cumulative sum by date
SELECT 
    d.date,
    d.quarter,
    d.year,
    SUM(f.amount) as total_sales
FROM fact_sales f
JOIN dim_date d ON f.date_id = d.date_id
GROUP BY 
    d.date,
    d.quarter,
    d.year
ORDER BY d.date;

-- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: Use CTE –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
WITH monthly_sales AS (
    SELECT 
        DATE_TRUNC(transaction_date, 'MONTH') as month,
        SUM(amount) as monthly_total
    FROM fact_sales
    GROUP BY DATE_TRUNC(transaction_date, 'MONTH')
)
SELECT 
    month,
    monthly_total,
    LAG(monthly_total) OVER (ORDER BY month) as cumulative_total
FROM monthly_sales;
```

4. **Python Processing**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π pandas –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('raw_data.csv', parse_dates=['date'])

# Clean data
df = df.dropna(subset=['email', 'phone'])
df = df.drop_duplicates()

# Feature engineering
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['quarter'] = df['date'].dt.quarter

# Data validation
df = df[df['amount'] > 0]  # Remove refunds
df = df[df['amount'] < df['amount'].quantile(0.99)]  # Remove outliers

# Save processed data
df.to_csv('processed_data.csv', index=False)
```

5. **Power BI Dashboard**
```powerquery
// ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π DAX –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
EVALUATE
    VAR TotalSales = SUM(fact_sales[amount])
    VAR AvgOrderValue = AVERAGE(fact_sales[amount])
RETURN
    DIVIDE(TotalSales, AvgOrderValue, 0)
```

6. **Tableau Dashboard**
```tableau
// ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–π calculated fields
- –°–æ–∑–¥–∞–π parameter "Target Sales"
- –°–æ–∑–¥–∞–π calculated field "Variance from Target"
- –ò—Å–ø–æ–ª—å–∑—É–π LOD (Level of Detail) –¥–ª—è –¥—Ä–∏–ª-–¥–∞—É–Ω
- –î–æ–±–∞–≤—å tooltips —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
```

#### –ß–µ–∫–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º:
- [ ] dbt –º–æ–¥–µ–ª–∏ follow naming conventions
- [ ] Airflow DAG –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–µ–Ω
- [ ] Incremental loading —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
- [ ] Data lineage –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è
- [ ] Data quality checks –≤–∫–ª—é—á–µ–Ω—ã
- [ ] SQL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç window functions/CTE
- [ ] Power BI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DAX –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
- [ ] Tableau –∏—Å–ø–æ–ª—å–∑—É–µ—Ç calculated fields
- [ ] Error handling –≤ ETL –ø–∞–π–ø–ª–∞–π–Ω–µ
- [ ] –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è BI

### –§–ê–ó–ê 3: Data Validator (–ü—Ä–æ–≤–µ—Ä–∫–∞)

–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ Data Validator.

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–µ–∫–∞:
```python
# ‚ùå FAIL –µ—Å–ª–∏:
import pandas as pd
from some_random_etl_lib  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
```

```yaml
# ‚ùå FAIL –µ—Å–ª–∏ ETL pipeline:
- Ê≤°Êúâ data quality checks
- Ê≤°Êúâ lineage tracking
- Ê≤°Êúâ incremental loading
- Ê≤°Êúâ error handling
- Ê≤°Êúâ data profiling

# ‚ùå FAIL –µ—Å–ª–∏ Data Warehouse:
- Ê≤°Êúâ proper indexes
- Ê≤°Êúâ partitioning strategy
- Ê≤°Êúâ vacuum/analyze optimization
```

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö:
```sql
-- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
-- Check for duplicates
SELECT 
    date_id,
    COUNT(*) as duplicate_count
FROM fact_sales
GROUP BY date_id
HAVING COUNT(*) > 1;

-- Check for NULL values
SELECT 
    COUNT(*) - COUNT(customer_id) as null_customers
FROM fact_sales;

-- Check for data integrity
SELECT 
    SUM(f.amount) as total_amount,
    COUNT(*) as transaction_count
FROM fact_sales
```

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ SQL:
```sql
-- ‚ùå FAIL –µ—Å–ª–∏:
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è SELECT * –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
- –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç WHERE clause –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
- –ù–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π (indexes, partitioning)
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è CROSS JOIN –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –ù–µ—Ç LIMIT –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏

-- ‚úÖ PASS –µ—Å–ª–∏:
- –Ø–≤–Ω–æ–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è indexes
- –†–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π partitioning
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∑–∞–ø—Ä–æ—Å—ã
- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–ª–∞–Ω –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è (maintenance)
```

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:
```yaml
# ‚ùå FAIL –µ—Å–ª–∏ Dashboard:
- –ù–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (date range, etc.)
- –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—à–ª—ã–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏ (YoY, WoW)
- –ù–µ—Ç KPI indicators
- –ù–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ business questions

# ‚úÖ PASS –µ—Å–ª–∏ Dashboard:
- –ü–æ–∑–≤–æ–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–∞–º, –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥—ã (YoY, WoW)
- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç KPI metrics
- –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ drill-down
- Ad-hoc –∞–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–µ–Ω
```

#### –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:

**–ï–°–õ–ò –û–®–ò–ë–ö–ê:**
```markdown
‚õî DATA VALIDATION FAILED

–ü—Ä–∏—á–∏–Ω–∞: [–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞]
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç: [ETL/DW/Dashboard]
–ê—Ä—Ç–µ—Ñ–∞–∫—Ç: [–∏–º—è –º–æ–¥–µ–ª–∏/–¥–∞—à–±–æ—Ä–¥–∞]

–ù–∞—Ä—É—à–µ–Ω–∏–µ:
- [–ü—Ä–∞–≤–∏–ª–æ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞]
- [–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ]

–î–µ–π—Å—Ç–≤–∏–µ: –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É, —Å–æ–±–ª—é–¥–∞—è –ø—Ä–æ—Ç–æ–∫–æ–ª

–í–æ–∑–≤—Ä–∞—Ç –∫ –§–ê–ó–ï 2
```

**–ï–°–õ–ò –í–°–Å OK:**
```markdown
‚úÖ DATA VALIDATION PASSED

–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:
- ‚úÖ dbt –º–æ–¥–µ–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
- ‚úÖ Airflow DAG –æ–ø—Ç–∏–º–∞–ª–µ–Ω
- ‚úÖ SQL –∑–∞–ø—Ä–æ—Å—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ Data quality checks —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã
- ‚úÖ Dashboard –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–µ–Ω
- ‚úÖ Business KPI –æ—Ç–æ–±—Ä–∞–∂–µ–Ω—ã

–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.
```

## üöÄ –ß–∞—Å—Ç—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

### S1: –°–æ–∑–¥–∞–Ω–∏–µ ETL –ø–∞–π–ø–ª–∞–π–Ω–∞

1. **Data Architect:** –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ—Ç dbt –º–æ–¥–µ–ª–∏ –∏ Airflow DAG
2. **Data Engineer:** –†–µ–∞–ª–∏–∑—É–µ—Ç SQL –º–æ–¥–µ–ª–∏ –∏ Airflow tasks
3. **Data Validator:** –ü—Ä–æ–≤–µ—Ä—è–µ—Ç data lineage –∏ –∫–∞—á–µ—Å—Ç–≤–æ

### S2: –°–æ–∑–¥–∞–Ω–∏–µ BI Dashboard

1. **Data Architect:** –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç KPI –∏ –º–µ—Ç—Ä–∏–∫–∏
2. **Data Engineer:** –°–æ–∑–¥–∞—ë—Ç Power BI/Tableau –¥–∞—à–±–æ—Ä–¥
3. **Data Validator:** –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

### S3: Real-time analytics

1. **Data Architect:** –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ—Ç Kafka+ClickHouse –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
2. **Data Engineer:** –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Confluent –∏ Superset
3. **Data Validator:** –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å

---

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

- [dbt Documentation](https://docs.getdbt.com/)
- [Airflow Guide](https://airflow.apache.org/docs/)
- [Power BI Documentation](https://learn.microsoft.com/power-bi/)
- [Tableau Documentation](https://help.tableau.com/)
